{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf0eb9ff-c339-43e2-ba29-14ae29cf247b",
   "metadata": {},
   "source": [
    "## Part-of-speech tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0bc71f-3dd7-4345-84df-e04c174af39b",
   "metadata": {},
   "source": [
    "The directory `pos_tagging` is to perform part-of-speech tagging based on the training data.\n",
    "\n",
    "### Approaches\n",
    "\n",
    "I created a first-order HMM model on `pos_tagging.py`, in which POS tags are approximately predicted by the following equation:\n",
    "\n",
    "$$ \\hat{t}_{1:n} = argmax_{t_i \\cdots t_n} \\prod_{i = 1}^n P(w_i|t_i)P(t_i|t_{i - 1}) $$\n",
    "\n",
    "where $P(w_i|t_i)$ is called emission probability and $P(t_i|t_{i - 1})$ transition probability. In order to calculate the emission probability when $w_i$ is unseen in the training data, I performed the following smoothing:\n",
    "\n",
    "$$ P(w_i|t_i) = \\lambda P(w_i|t_i) + (1 - \\lambda) \\frac{1}{N_{t_i}} $$\n",
    "\n",
    "where $N_{t_i}$ is the vocabulary size calculated as the unique number of tokens emitted from $t_i$ plus $1$, which represents `<UNK>`.  \n",
    "\n",
    "To explore the appropriate value for $\\lambda$, I conducted hyperparameter tuning using `tuning.py`. As a result, the highest accuracy was obtained when $\\lambda = 0.99999$.\n",
    "\n",
    "### Results\n",
    "\n",
    "The highest accuracy achieved was $86.87%$. To calculate this, run `eval/gradepos.pl eval/pred.txt eval/wiki-en-test.pos`, whose `gradepos.pl` is obtained [here](https://github.com/neubig/nlptutorial/tree/master/script)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257273b1-4a49-4eeb-93c4-8e30206541a4",
   "metadata": {},
   "source": [
    "## Dependency Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d989bf-1239-4940-8f28-567b5db84c7a",
   "metadata": {},
   "source": [
    "The directory `depend_parsing` is to perform dependency parsing based on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28d72c8-d530-4692-93e1-8305b760115f",
   "metadata": {},
   "source": [
    "---\n",
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1954d2d-f63f-4387-a758-726d3e8fe616",
   "metadata": {},
   "source": [
    "For both of the above tasks, submitted codes are tested by Python 3.9.9 with packages specified in the `requirements.txt` in each directory.\n",
    "\n",
    "To download data, after executing `cd data` in each directory, run the following code for part-of-speech tagging\n",
    "```\n",
    "wget https://raw.githubusercontent.com/neubig/nlptutorial/master/data/wiki-en-train.norm_pos\n",
    "wget https://raw.githubusercontent.com/neubig/nlptutorial/master/data/wiki-en-test.norm_pos\n",
    "```\n",
    "and the following for dependency parsing.\n",
    "```\n",
    "wget https://raw.githubusercontent.com/neubig/nlptutorial/master/data/mstparser-en-train.dep\n",
    "wget https://raw.githubusercontent.com/neubig/nlptutorial/master/data/mstparser-en-test.dep\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
