{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c918698b-8a34-4b3e-b02c-50ea4066ff66",
   "metadata": {},
   "source": [
    "# Part-of-speech tagging\n",
    "\n",
    "This directory is for a project to perform part-of-speech tagging based on a given training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e73262-fc5e-4daa-8074-168c8e29a494",
   "metadata": {},
   "source": [
    "## Approaches\n",
    "\n",
    "I created a first-order HMM model, in which POS tags are approximately predicted by the following equation:\n",
    "\n",
    "$$ \\hat{t}_{1:n} = argmax_{t_i \\cdots t_n} \\prod_{i = 1}^n P(w_i|t_i)P(t_i|t_{i - 1}) $$\n",
    "\n",
    "where $P(w_i|t_i)$ is called emission probability and $P(t_i|t_{i - 1})$ transition probability. In order to calculate the emission probability when $w_i$ is unseen in the training data, I performed the following smoothing:\n",
    "\n",
    "$$ P(w_i|t_i) = \\lambda P(w_i|t_i) + (1 - \\lambda) \\frac{1}{N_{t_i}} $$\n",
    "\n",
    "where $N_{t_i}$ is the vocabulary size calculated as the unique number of tokens emitted from $t_i$ plus $1$, which represents `<UNK>`.  \n",
    "\n",
    "To explore the appropriate value for $\\lambda$, I conducted hyperparameter tuning using `tuning.py`. As a result, the highest accuracy was obtained when $\\lambda = 0.99999$.\n",
    "\n",
    "## Results\n",
    "\n",
    "The highest accuracy achieved was $86.87%$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fbf0c8-177d-40c8-b723-6d583cb7790b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67001221-b482-43aa-b387-ed7755747198",
   "metadata": {},
   "source": [
    "## Install Packages\n",
    "\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "The project is tested by Python 3.9.9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb5a56d-be49-48eb-98fc-25863baa0f70",
   "metadata": {},
   "source": [
    "## Download Data\n",
    "\n",
    "```\n",
    "cd data\n",
    "wget https://raw.githubusercontent.com/neubig/nlptutorial/master/data/wiki-en-train.norm_pos\n",
    "wget https://raw.githubusercontent.com/neubig/nlptutorial/master/data/wiki-en-test.norm_pos\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84c78cc-5dd0-4b00-a250-ca276874dc26",
   "metadata": {},
   "source": [
    "## Train and Predict\n",
    "\n",
    "```\n",
    "python pos_tagging.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf69de9-95cf-48cb-8f8e-d361690949f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Evaluate\n",
    "\n",
    "```\n",
    "eval/gradepos.pl eval/pred.txt eval/wiki-en-test.pos\n",
    "```\n",
    "\n",
    "The program `gradepos.pl` was obtained [here](https://github.com/neubig/nlptutorial/tree/master/script)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
